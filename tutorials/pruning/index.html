<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/bitstream-hackathon/libs/highlight/github.min.css"> <link rel=stylesheet  href="/bitstream-hackathon/css/jtd.css"> <link rel=icon  href="/bitstream-hackathon/assets/favicon.ico"> <title>Pruning Tutorial</title> <div class=page-wrap > <div class=side-bar > <!-- <div class=header > <a href="/bitstream-hackathon/" class=title > <img src="/bitstream-hackathon/assets/pharm_homepage.pdf"> </a> </div> --> <label for=show-menu  class=show-menu >MENU</label> <input type=checkbox  id=show-menu  role=button > <div class=menu  id=side-menu > <ul class=menu-list > <li class="menu-list-item "><a href="/bitstream-hackathon/" class="menu-list-link ">Home</a> <li class=menu-list-item >Tutorials <ul class=menu-list-child-list  style="display: block;"> <li class="menu-list-item "><a href="/bitstream-hackathon/tutorials/overview/" class="menu-list-link ">Overview</a> <li class="menu-list-item "><a href="/bitstream-hackathon/tutorials/bitstream/" class="menu-list-link ">Bitstreams 101</a> <li class="menu-list-item active"><a href="/bitstream-hackathon/tutorials/pruning/" class="menu-list-link active">Pruning</a> </ul> </ul> </div> <div class=footer > This is <em>Just the docs</em>, adapted from the <a href="https://github.com/pmarsceill/just-the-docs" target=_blank >Jekyll theme</a>. </div> </div> <div class=main-content-wrap > <div class=main-content > <div class=main-header > <span style="padding-right: 250px;"> <img src="/bitstream-hackathon/assets/red-flush-UWlogo.pdf" width=150px > <img src="/bitstream-hackathon/assets/pharm_homepage.pdf" width=175px  style="padding-bottom: 10px;"> </span> <a id=github  href="/bitstream-hackathon//github.com/UW-PHARM/BitSAD.jl">BitSAD.jl on GitHub</a> </div> <div class=franklin-content ><em>Make sure you have completed the <a href="/bitstream-hackathon/tutorials/overview">getting started</a> tutorial.</em></p> <p><strong>Table of contents:</strong></p> <p><div class=franklin-toc ><ol><li><a href="#introduction">Introduction</a></ol></div> <h1 id=pruning_tutorial ><a href="#pruning_tutorial" class=header-anchor >Pruning tutorial</a></h1> <h2 id=introduction ><a href="#introduction" class=header-anchor >Introduction</a></h2> <p>Deep learning has achieved unprecedented performance on image recognition tasks like ImageNet and natural language processing tasks such as question answering and machine translation. These models generally are on the order of millions or even billions of parameters. For example, Google&#39;s recent released large language model, <a href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html">Pathways Language Model &#40;PaLM&#41;</a>, can do well on tasks like conceptual understanding and cause &amp; effect reasoning and contains over 540 Billion parameters&#33;</p> <p>While this is great for advancing state of the art &#40;SOTA&#41; in terms of accuracy, we have applications like self-driving cars or server-side video processing where we would want to deploy these models on the edge to meet real-time deadlines. By having models on the device, we can avoid the latency cost of sending a request to the server for the model to process and the result being back to the device. In these settings, we can&#39;t use these gigantic models for a few reasons: the on-device memory available is generally a couple hundred megabytes &#40;meaning we can&#39;t fit our model into memory&#41; and the number of operations it takes to obtain output from the model would fail constraints like latency and power. Luckily, we can rely on model compression to address these concerns.</p> <p>Model compression is the area of research focused on deploying SOTA models in resource-constrained devices while minimizing accuracy degradation. Various approaches to compressing a model include: weight pruning, quantization, knowledge distillation, low-rank tensor decomposition, hardware-aware neural architecture search, etc. In particular, we will discuss and target, arguably, the simplest of these methods: weight pruning.</p> <pre><code class=language-julia >include&#40;&quot;_tutorials/src/setup.jl&quot;&#41;;</code></pre>
<p>More stuff</p>
<pre><code class=language-julia >m &#61; MobileNet&#40;relu, 0.25; fcsize &#61; 64, nclasses &#61; 2&#41;
#</code></pre><pre><code class="plaintext code-output">Chain(
  Chain(
    Conv((3, 3), 3 => 8, pad=1, stride=2),  # 224 parameters
    BatchNorm(8, relu),                 # 16 parameters, plus 16
    Conv((3, 3), 8 => 8, pad=1, groups=8),  # 80 parameters
    BatchNorm(8, relu),                 # 16 parameters, plus 16
    Conv((1, 1), 8 => 16),              # 144 parameters
    BatchNorm(16, relu),                # 32 parameters, plus 32
    Conv((3, 3), 16 => 16, pad=1, stride=2, groups=16),  # 160 parameters
    BatchNorm(16, relu),                # 32 parameters, plus 32
    Conv((1, 1), 16 => 32),             # 544 parameters
    BatchNorm(32, relu),                # 64 parameters, plus 64
    Conv((3, 3), 32 => 32, pad=1, groups=32),  # 320 parameters
    BatchNorm(32, relu),                # 64 parameters, plus 64
    Conv((1, 1), 32 => 32),             # 1_056 parameters
    BatchNorm(32, relu),                # 64 parameters, plus 64
    Conv((3, 3), 32 => 32, pad=1, stride=2, groups=32),  # 320 parameters
    BatchNorm(32, relu),                # 64 parameters, plus 64
    Conv((1, 1), 32 => 64),             # 2_112 parameters
    BatchNorm(64, relu),                # 128 parameters, plus 128
    Conv((3, 3), 64 => 64, pad=1, groups=64),  # 640 parameters
    BatchNorm(64, relu),                # 128 parameters, plus 128
    Conv((1, 1), 64 => 64),             # 4_160 parameters
    BatchNorm(64, relu),                # 128 parameters, plus 128
    Conv((3, 3), 64 => 64, pad=1, stride=2, groups=64),  # 640 parameters
    BatchNorm(64, relu),                # 128 parameters, plus 128
    Conv((1, 1), 64 => 128),            # 8_320 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((3, 3), 128 => 128, pad=1, groups=128),  # 1_280 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((1, 1), 128 => 128),           # 16_512 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((3, 3), 128 => 128, pad=1, groups=128),  # 1_280 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((1, 1), 128 => 128),           # 16_512 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((3, 3), 128 => 128, pad=1, groups=128),  # 1_280 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((1, 1), 128 => 128),           # 16_512 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((3, 3), 128 => 128, pad=1, groups=128),  # 1_280 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((1, 1), 128 => 128),           # 16_512 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((3, 3), 128 => 128, pad=1, groups=128),  # 1_280 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((1, 1), 128 => 128),           # 16_512 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((3, 3), 128 => 128, pad=1, stride=2, groups=128),  # 1_280 parameters
    BatchNorm(128, relu),               # 256 parameters, plus 256
    Conv((1, 1), 128 => 256),           # 33_024 parameters
    BatchNorm(256, relu),               # 512 parameters, plus 512
    Conv((3, 3), 256 => 256, pad=1, groups=256),  # 2_560 parameters
    BatchNorm(256, relu),               # 512 parameters, plus 512
    Conv((1, 1), 256 => 256),           # 65_792 parameters
    BatchNorm(256, relu),               # 512 parameters, plus 512
  ),
  Chain(
    GlobalMeanPool(),
    MLUtils.flatten,
    Dense(256, 64, relu),               # 16_448 parameters
    Dense(64, 2),                       # 130 parameters
  ),
)         # Total: 112 trainable arrays, 232_386 parameters,
          # plus 54 non-trainable, 5_472 parameters, summarysize 950.117 KiB.</code></pre>


<div class=page-foot >
    <hr>
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> UW-Madison PHARM Group. Last modified: April 08, 2022.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div>
    </div> 
    </div> 
    </div> <!-- end of class page-wrap-->
    
    
      <script src="/bitstream-hackathon/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>